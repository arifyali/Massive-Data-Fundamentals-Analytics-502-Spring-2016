	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:70)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:56)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1932)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1873)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1853)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1825)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:565)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getBlockLocations(AuthorizationProviderProxyClientProtocol.java:87)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:363)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1060)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)

	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at com.sun.proxy.$Proxy15.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:252)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
	at com.sun.proxy.$Proxy16.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1258)
	... 20 more

16/01/22 15:31:32 INFO mapreduce.Job: Task Id : attempt_1453470471698_0003_m_000000_1, Status : FAILED
Error: java.io.FileNotFoundException: Path is not a file: /user/cloudera/hamlet/input/Shakespear
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:70)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:56)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1932)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1873)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1853)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1825)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:565)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getBlockLocations(AuthorizationProviderProxyClientProtocol.java:87)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:363)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1060)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1260)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1245)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1233)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:302)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:268)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:260)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1564)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:308)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:304)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:304)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:775)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:85)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): Path is not a file: /user/cloudera/hamlet/input/Shakespear
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:70)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:56)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1932)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1873)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1853)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1825)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:565)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getBlockLocations(AuthorizationProviderProxyClientProtocol.java:87)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:363)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1060)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)

	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at com.sun.proxy.$Proxy15.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:252)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
	at com.sun.proxy.$Proxy16.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1258)
	... 20 more

16/01/22 15:31:40 INFO mapreduce.Job: Task Id : attempt_1453470471698_0003_m_000000_2, Status : FAILED
Error: java.io.FileNotFoundException: Path is not a file: /user/cloudera/hamlet/input/Shakespear
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:70)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:56)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1932)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1873)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1853)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1825)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:565)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getBlockLocations(AuthorizationProviderProxyClientProtocol.java:87)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:363)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1060)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1260)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1245)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1233)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:302)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:268)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:260)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1564)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:308)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:304)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:304)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:775)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:85)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): Path is not a file: /user/cloudera/hamlet/input/Shakespear
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:70)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:56)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1932)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1873)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1853)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1825)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:565)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getBlockLocations(AuthorizationProviderProxyClientProtocol.java:87)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:363)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1060)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)

	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at com.sun.proxy.$Proxy15.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:252)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
	at com.sun.proxy.$Proxy16.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1258)
	... 20 more

16/01/22 15:31:53 INFO mapreduce.Job:  map 100% reduce 100%
16/01/22 15:31:53 INFO mapreduce.Job: Job job_1453470471698_0003 failed with state FAILED due to: Task failed task_1453470471698_0003_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0

16/01/22 15:31:53 INFO mapreduce.Job: Counters: 8
	Job Counters 
		Failed map tasks=4
		Launched map tasks=4
		Other local map tasks=4
		Total time spent by all maps in occupied slots (ms)=30796
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=30796
		Total vcore-seconds taken by all map tasks=30796
		Total megabyte-seconds taken by all map tasks=31535104
[cloudera@quickstart HW1]$ hdfs dfs -rm -r  /user/cloudera/hamlet/output16/01/22 15:32:21 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /user/cloudera/hamlet/output
[cloudera@quickstart HW1]$ hadoop jar WordCount.jar WordCount /user/cloudera/hamlet/input/^C                                          /user/cloudera/hamlet/output/
[cloudera@quickstart HW1]$ ^C
[cloudera@quickstart HW1]$ hadoop jar WordCount.jar WordCount /user/cloudera/hamlet/input/Shakespear                                            /user/cloudera/hamlet/output/
16/01/22 15:33:28 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/01/22 15:33:29 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/01/22 15:33:29 INFO input.FileInputFormat: Total input paths to process : 39
16/01/22 15:33:30 INFO mapreduce.JobSubmitter: number of splits:39
16/01/22 15:33:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1453470471698_0004
16/01/22 15:33:31 INFO impl.YarnClientImpl: Submitted application application_1453470471698_0004
16/01/22 15:33:31 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1453470471698_0004/
16/01/22 15:33:31 INFO mapreduce.Job: Running job: job_1453470471698_0004
16/01/22 15:33:44 INFO mapreduce.Job: Job job_1453470471698_0004 running in uber mode : false
16/01/22 15:33:44 INFO mapreduce.Job:  map 0% reduce 0%
16/01/22 15:34:55 INFO mapreduce.Job:  map 2% reduce 0%
16/01/22 15:34:59 INFO mapreduce.Job:  map 4% reduce 0%
16/01/22 15:35:03 INFO mapreduce.Job:  map 5% reduce 0%
16/01/22 15:35:04 INFO mapreduce.Job:  map 6% reduce 0%
16/01/22 15:35:06 INFO mapreduce.Job:  map 8% reduce 0%
16/01/22 15:35:10 INFO mapreduce.Job:  map 9% reduce 0%
16/01/22 15:35:11 INFO mapreduce.Job:  map 10% reduce 0%
16/01/22 15:35:12 INFO mapreduce.Job:  map 12% reduce 0%
16/01/22 15:35:13 INFO mapreduce.Job:  map 13% reduce 0%
16/01/22 15:35:15 INFO mapreduce.Job:  map 14% reduce 0%
16/01/22 15:35:16 INFO mapreduce.Job:  map 15% reduce 0%
16/01/22 15:36:13 INFO mapreduce.Job:  map 19% reduce 0%
16/01/22 15:36:14 INFO mapreduce.Job:  map 21% reduce 0%
16/01/22 15:36:16 INFO mapreduce.Job:  map 22% reduce 0%
16/01/22 15:36:17 INFO mapreduce.Job:  map 24% reduce 0%
16/01/22 15:36:20 INFO mapreduce.Job:  map 25% reduce 0%
16/01/22 15:36:21 INFO mapreduce.Job:  map 26% reduce 0%
16/01/22 15:36:23 INFO mapreduce.Job:  map 27% reduce 0%
16/01/22 15:36:25 INFO mapreduce.Job:  map 28% reduce 0%
16/01/22 15:36:33 INFO mapreduce.Job:  map 30% reduce 0%
16/01/22 15:36:37 INFO mapreduce.Job:  map 31% reduce 0%
16/01/22 15:37:15 INFO mapreduce.Job:  map 31% reduce 10%
16/01/22 15:37:18 INFO mapreduce.Job:  map 32% reduce 10%
16/01/22 15:37:19 INFO mapreduce.Job:  map 34% reduce 10%
16/01/22 15:37:20 INFO mapreduce.Job:  map 37% reduce 10%
16/01/22 15:37:22 INFO mapreduce.Job:  map 38% reduce 11%
16/01/22 15:37:25 INFO mapreduce.Job:  map 38% reduce 13%
16/01/22 15:37:27 INFO mapreduce.Job:  map 41% reduce 13%
16/01/22 15:37:29 INFO mapreduce.Job:  map 41% reduce 14%
16/01/22 15:37:36 INFO mapreduce.Job:  map 43% reduce 14%
16/01/22 15:37:38 INFO mapreduce.Job:  map 44% reduce 14%
16/01/22 15:37:42 INFO mapreduce.Job:  map 44% reduce 15%
16/01/22 15:38:12 INFO mapreduce.Job:  map 45% reduce 15%
16/01/22 15:38:16 INFO mapreduce.Job:  map 47% reduce 15%
16/01/22 15:38:17 INFO mapreduce.Job:  map 48% reduce 15%
16/01/22 15:38:18 INFO mapreduce.Job:  map 49% reduce 15%
16/01/22 15:38:19 INFO mapreduce.Job:  map 50% reduce 15%
16/01/22 15:38:20 INFO mapreduce.Job:  map 50% reduce 16%
16/01/22 15:38:23 INFO mapreduce.Job:  map 51% reduce 16%
16/01/22 15:38:24 INFO mapreduce.Job:  map 51% reduce 17%
16/01/22 15:38:27 INFO mapreduce.Job:  map 53% reduce 17%
16/01/22 15:38:31 INFO mapreduce.Job:  map 54% reduce 17%
16/01/22 15:38:34 INFO mapreduce.Job:  map 54% reduce 18%
16/01/22 15:38:39 INFO mapreduce.Job:  map 56% reduce 18%
16/01/22 15:38:52 INFO mapreduce.Job:  map 56% reduce 19%
16/01/22 15:39:25 INFO mapreduce.Job:  map 58% reduce 19%
16/01/22 15:39:26 INFO mapreduce.Job:  map 60% reduce 19%
16/01/22 15:39:28 INFO mapreduce.Job:  map 62% reduce 19%
16/01/22 15:39:30 INFO mapreduce.Job:  map 63% reduce 19%
16/01/22 15:39:32 INFO mapreduce.Job:  map 64% reduce 21%
16/01/22 15:39:36 INFO mapreduce.Job:  map 66% reduce 21%
16/01/22 15:39:38 INFO mapreduce.Job:  map 67% reduce 22%
16/01/22 15:39:49 INFO mapreduce.Job:  map 68% reduce 22%
16/01/22 15:39:53 INFO mapreduce.Job:  map 69% reduce 22%
16/01/22 15:39:55 INFO mapreduce.Job:  map 69% reduce 23%
16/01/22 15:40:26 INFO mapreduce.Job:  map 73% reduce 23%
16/01/22 15:40:28 INFO mapreduce.Job:  map 74% reduce 23%
16/01/22 15:40:30 INFO mapreduce.Job:  map 75% reduce 23%
16/01/22 15:40:31 INFO mapreduce.Job:  map 76% reduce 23%
16/01/22 15:40:32 INFO mapreduce.Job:  map 76% reduce 25%
16/01/22 15:40:34 INFO mapreduce.Job:  map 77% reduce 25%
16/01/22 15:40:35 INFO mapreduce.Job:  map 77% reduce 26%
16/01/22 15:40:38 INFO mapreduce.Job:  map 79% reduce 26%
16/01/22 15:40:49 INFO mapreduce.Job:  map 82% reduce 26%
16/01/22 15:40:54 INFO mapreduce.Job:  map 82% reduce 27%
16/01/22 15:41:23 INFO mapreduce.Job:  map 84% reduce 27%
16/01/22 15:41:24 INFO mapreduce.Job:  map 86% reduce 27%
16/01/22 15:41:25 INFO mapreduce.Job:  map 87% reduce 27%
16/01/22 15:41:26 INFO mapreduce.Job:  map 87% reduce 28%
16/01/22 15:41:27 INFO mapreduce.Job:  map 89% reduce 28%
16/01/22 15:41:29 INFO mapreduce.Job:  map 90% reduce 29%
16/01/22 15:41:32 INFO mapreduce.Job:  map 92% reduce 30%
16/01/22 15:41:35 INFO mapreduce.Job:  map 92% reduce 31%
16/01/22 15:41:43 INFO mapreduce.Job:  map 95% reduce 31%
16/01/22 15:41:45 INFO mapreduce.Job:  map 95% reduce 32%
16/01/22 15:42:00 INFO mapreduce.Job:  map 100% reduce 32%
16/01/22 15:42:01 INFO mapreduce.Job:  map 100% reduce 60%
16/01/22 15:42:03 INFO mapreduce.Job:  map 100% reduce 100%
16/01/22 15:42:04 INFO mapreduce.Job: Job job_1453470471698_0004 completed successfully
16/01/22 15:42:04 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=3908114
		FILE: Number of bytes written=12280630
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10799460
		HDFS: Number of bytes written=724867
		HDFS: Number of read operations=120
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Killed map tasks=2
		Launched map tasks=41
		Launched reduce tasks=1
		Data-local map tasks=41
		Total time spent by all maps in occupied slots (ms)=2482055
		Total time spent by all reduces in occupied slots (ms)=341927
		Total time spent by all map tasks (ms)=2482055
		Total time spent by all reduce tasks (ms)=341927
		Total vcore-seconds taken by all map tasks=2482055
		Total vcore-seconds taken by all reduce tasks=341927
		Total megabyte-seconds taken by all map tasks=2541624320
		Total megabyte-seconds taken by all reduce tasks=350133248
	Map-Reduce Framework
		Map input records=246233
		Map output records=1781870
		Map output bytes=16896950
		Map output materialized bytes=3908342
		Input split bytes=6391
		Combine input records=1781870
		Combine output records=286611
		Reduce input groups=67505
		Reduce shuffle bytes=3908342
		Reduce input records=286611
		Reduce output records=67505
		Spilled Records=573222
		Shuffled Maps =39
		Failed Shuffles=0
		Merged Map outputs=39
		GC time elapsed (ms)=45821
		CPU time spent (ms)=111730
		Physical memory (bytes) snapshot=8741588992
		Virtual memory (bytes) snapshot=60061933568
		Total committed heap usage (bytes)=6517059584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10793069
	File Output Format Counters 
		Bytes Written=724867
[cloudera@quickstart HW1]$ dfs dfs -ls /user/cloudera/hamlet/output/
bash: dfs: command not found
[cloudera@quickstart HW1]$ hdfs dfs -ls /user/cloudera/hamlet/output/
Found 2 items
-rw-r--r--   1 cloudera cloudera          0 2016-01-22 15:42 /user/cloudera/hamlet/output/_SUCCESS
-rw-r--r--   1 cloudera cloudera     724867 2016-01-22 15:42 /user/cloudera/hamlet/output/part-r-00000
[cloudera@quickstart HW1]$ hdfs dfs -ls dfs dfs -ls /user/cloudera/hamlet/output/part-r-00000
ls: `dfs': No such file or directory
ls: `dfs': No such file or directory
ls: `-ls': No such file or directory
-rw-r--r--   1 cloudera cloudera     724867 2016-01-22 15:42 /user/cloudera/hamlet/output/part-r-00000
[cloudera@quickstart HW1]$ hdfs dfs -tail /user/cloudera/hamlet/output/part-r-00000
21
you-	90
you--	2
you--you	2
you-I	2
you-he	2
you-often	2
you-pray	2
you-that	2
you-well,	2
you-wondrous	2
you.	1601
you.'	8
you.-	10
you:	57
you;	510
you?	512
you?'	6
young	667
young'	2
young's	2
young'st	2
young,	72
young-ey'd	2
young.	17
young;	15
young?	4
younger	48
younger,	4
younger.	4
youngest	38
youngest,	2
youngest;	2
younglings,	2
youngly	4
younker	6
your	11868
your-	2
your@login	1
yours	153
yours!	6
yours,	119
yours-	10
yours--	2
yours-not	2
yours.	124
yours.'	2
yours:	8
yours;	42
yours?	24
yourself	288
yourself!	6
yourself,	91
yourself.	82
yourself:	10
yourself;	34
yourself?	18
yourselves	66
yourselves!	2
yourselves,	32
yourselves.	30
yourselves:	2
yourselves;	6
yourselves?	8
youth	273
youth!	11
youth's	10
youth,	140
youth-	5
youth.	44
youth.'	2
youth:	2
youth;	28
youth?	9
youthful	56
youthful,	4
youths	8
youtli	2
zanies.	2
zany,	2
zeal	40
zeal!	2
zeal,	14
zeal.	8
zealous	12
zeals,	2
zed!	2
zenith	2
zephyrs	2
zip	1
zir,	2
zir.	2
zo	2
zodiac	2
zodiacs	2
zone,	2
zounds!	2
zounds,	2
zwagger'd	2
}	4
[cloudera@quickstart HW1]$ ^C
[cloudera@quickstart HW1]$ ^C
[cloudera@quickstart HW1]$ 

